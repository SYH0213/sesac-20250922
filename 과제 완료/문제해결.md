## 2️⃣ [03- Use-Cases] 모델 변경, 매개변수 & 버전 이슈 정리

### 문제 상황
LangGraph 기반 SQL Agent 파이프라인을 OpenAI 모델에서 Google **Gemini (`ChatGoogleGenerativeAI`)** 모델로 교체하는 과정에서, OpenAI에서는 정상 동작하던 쿼리 검증 노드가 Gemini에서는 에러를 발생시켰다.

```text
InvalidArgument: 400 Please ensure that single turn requests end with a user role or the role field is empty.
```
## 원인 분석

- Gemini API는 입력 메시지(messages)가 마지막에 반드시 user 역할로 끝나야 한다는 제약이 있었다.

- 기존 파이프라인에서는 AIMessage(assistant 역할) 상태 그대로 invoke()에 전달 → 오류 발생.

## 해결 방법

마지막 메시지를 HumanMessage로 래핑하여 항상 user 역할로 변환 후 전달하도록 수정하였다.


def model_check_query(state: State) -> dict[str, list[AIMessage]]:
    """
    Use this tool to check that your query is correct before you run it
    """
    return {"messages": [query_check.invoke({"messages": [state["messages"][-1]]})]}

# ↓↓↓

from langchain_core.messages import HumanMessage

def model_check_query(state: State) -> dict[str, list[AIMessage]]:
    """
    Ensure query checking is always done with a user role message.
    """
    last_msg = state["messages"][-1]
    
    # 만약 assistant 메시지라면 user 메시지로 감싸기
    if last_msg.type != "human":
        last_msg = HumanMessage(content=last_msg.content)

    return {"messages": [query_check.invoke({"messages": [last_msg]})]}


## 결과

- 수정 이후, Gemini 모델에서도 파이프라인이 정상 작동함을 확인.

- OpenAI와 Gemini 간의 메시지 형식 제약 차이를 직접 경험하면서, 단순히 모델명 교체만으로는 완전한 호환이 되지 않음을 알 수 있었다.

## 배운 점

- 모델 제공사별 제약 차이를 반드시 고려해야 한다.

- 에러 메시지를 통해 원인을 추적하고, 직접 부딪히며 해결하는 과정에서 학습 효과가 크다.

- 매개변수, 버전, 메시지 포맷 등은 “직접 실행 → 오류 확인 → 원인 분석 → 코드 보정” 단계를 거쳐야 한다는 점을 체감했다.